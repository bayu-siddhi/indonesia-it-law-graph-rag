{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import dateparser\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "# from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scraping Regulation Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_selected_regulations(file_path: str, sheet_name: str, url_type: str = 'url_1',\n",
    "                                    url_only: bool = True ) -> list[str] | list[dict]:\n",
    "\n",
    "    # Read All Regulation with 'used' == 1\n",
    "    selected_regulations = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    selected_regulations = selected_regulations.loc[selected_regulations['used'] == 1].copy()\n",
    "    if url_only:\n",
    "        return selected_regulations[url_type].tolist()\n",
    "    else:\n",
    "        selected_regulations = selected_regulations.loc[selected_regulations[url_type].notna()].copy()\n",
    "        selected_regulations = selected_regulations.loc[:, ['name', url_type]].copy()\n",
    "        selected_regulations.rename(columns={'name': 'name', url_type: 'url'}, inplace=True)\n",
    "        return selected_regulations.to_dict(orient='records')\n",
    "\n",
    "# Change These Input\n",
    "filename = 'dataset.xlsx'\n",
    "dir_path = os.path.join('data', 'active')\n",
    "file_path = os.path.join(dir_path, filename)\n",
    "\n",
    "uu = load_excel_selected_regulations(file_path=file_path, sheet_name='UU', url_type='url_1', url_only=True)\n",
    "pp = load_excel_selected_regulations(file_path=file_path, sheet_name='PP', url_type='url_1', url_only=True)\n",
    "permenkominfo = load_excel_selected_regulations(file_path=file_path, sheet_name='PERMENKOMINFO', url_type='url_1', url_only=True)\n",
    "\n",
    "selected_regulations = uu + pp + permenkominfo\n",
    "print(f'Total regulations: {len(selected_regulations)}')\n",
    "display(selected_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPKScraper:\n",
    "\n",
    "    def __init__(self, web_driver: WebDriver):\n",
    "        self.web_driver = web_driver\n",
    "        self.ENCODE = {\n",
    "            'type': {\n",
    "                'UU': '01',\n",
    "                'PERPPU': '02',\n",
    "                'PP': '03',\n",
    "                'PERPRES': '04',\n",
    "                'PERMENKOMINFO': '05'\n",
    "            },\n",
    "            'section': {\n",
    "                'document': '1',\n",
    "                'considering': '2',\n",
    "                'observing': '3',\n",
    "                'definition': '4',\n",
    "                'chapter': '5',\n",
    "                'article': '6',\n",
    "                'section': '7',\n",
    "            }\n",
    "        }\n",
    "        self.WORD_TO_NUMBER = {\n",
    "            \"kesatu\": 1, \"kedua\": 2, \"ketiga\": 3, \"keempat\": 4, \"kelima\": 5,\n",
    "            \"keenam\": 6, \"ketujuh\": 7, \"kedelapan\": 8, \"kesembilan\": 9, \"kesepuluh\": 10,\n",
    "            \"kesebelas\": 11, \"kedua belas\": 12, \"ketiga belas\": 13, \"keempat belas\": 14, \"kelima belas\": 15,\n",
    "            \"keenam belas\": 16, \"ketujuh belas\": 17, \"kedelapan belas\": 18, \"kesembilan belas\": 19, \"kedua puluh\": 20,\n",
    "            \"kedua puluh satu\": 21, \"kedua puluh dua\": 22, \"kedua puluh tiga\": 23, \"kedua puluh empat\": 24, \"kedua puluh lima\": 25,\n",
    "            \"kedua puluh enam\": 26, \"kedua puluh tujuh\": 27, \"kedua puluh delapan\": 28, \"kedua puluh sembilan\": 29, \"ketiga puluh\": 30,\n",
    "            \"ketiga puluh satu\": 31, \"ketiga puluh dua\": 32, \"ketiga puluh tiga\": 33, \"ketiga puluh empat\": 34, \"ketiga puluh lima\": 35,\n",
    "            \"ketiga puluh enam\": 36, \"ketiga puluh tujuh\": 37, \"ketiga puluh delapan\": 38, \"ketiga puluh sembilan\": 39, \"keempat puluh\": 40,\n",
    "            \"keempat puluh satu\": 41, \"keempat puluh dua\": 42, \"keempat puluh tiga\": 43, \"keempat puluh empat\": 44, \"keempat puluh lima\": 45,\n",
    "            \"keempat puluh enam\": 46, \"keempat puluh tujuh\": 47, \"keempat puluh delapan\": 48, \"keempat puluh sembilan\": 49, \"kelima puluh\": 50\n",
    "        }\n",
    "    \n",
    "    \n",
    "    @staticmethod  # https://stackoverflow.com/questions/735975/static-methods-in-python\n",
    "    def list_of_dict_to_json(regulation_data: list[dict], output_path: str) -> None:\n",
    "        if not output_path.endswith('.json'):\n",
    "            output_path = output_path + '.json'\n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(regulation_data, file, indent=4)\n",
    "        \n",
    "\n",
    "    def regulation_metadata(self, regulation_links: list[str], verbose: bool = True) -> list[dict]:\n",
    "        metadata_box_xpath = '/html/body/div/div/div[2]/div[2]/div/div[1]/div[2]/div'\n",
    "        download_box_xpath = '/html/body/div/div/div[2]/div[2]/div/div[2]/div[1]'\n",
    "        status_box_xpath = '/html/body/div/div/div[2]/div[2]/div/div[2]/div[2]'\n",
    "        metadata_inner_box_css_selector = 'div.container.fs-6'\n",
    "        status_inner_box_css_selector = 'div.container.fs-6'\n",
    "        status_type_patterns = r'(Dicabut dengan :|Diubah dengan :|Mengubah :|Mencabut :)'\n",
    "\n",
    "        # Final result\n",
    "        regulation_metadata = list()\n",
    "        durations = list()\n",
    "\n",
    "        # Iterate for all regulation links\n",
    "        for regulation_link in tqdm(iterable=regulation_links, desc='Scraping regulation metadata', disable=not verbose):\n",
    "            start = time.time()\n",
    "            \n",
    "            # Go to the page\n",
    "            access_page = False\n",
    "            trial_number = 10\n",
    "\n",
    "            for _ in range(trial_number):\n",
    "                try:\n",
    "                    # Try access the page\n",
    "                    self.web_driver.get(regulation_link)\n",
    "                    wait = WebDriverWait(self.web_driver, timeout=10)\n",
    "                    wait.until(EC.presence_of_element_located((By.XPATH, metadata_box_xpath)))\n",
    "                    wait.until(EC.presence_of_element_located((By.XPATH, download_box_xpath)))\n",
    "                    access_page = True\n",
    "                    break\n",
    "                except TimeoutException as e:\n",
    "                    # If timeout, wait for 2 seconds\n",
    "                    time.sleep(2)\n",
    "            \n",
    "            if not access_page:\n",
    "                if verbose:\n",
    "                    print(f'Unable to access {regulation_link} after {trial_number} attempts')\n",
    "                    print('Skip the scraping process to the next regulation link')\n",
    "                continue\n",
    "\n",
    "            # Extract metadata\n",
    "            ineffective = False\n",
    "            metadata_box = self.web_driver.find_element(By.XPATH, metadata_box_xpath)\n",
    "            metadata_inner_box = metadata_box.find_element(By.CSS_SELECTOR, metadata_inner_box_css_selector)\n",
    "            metadata_elements = metadata_inner_box.find_elements(By.XPATH, './*')[:-2]\n",
    "\n",
    "            for index, element in enumerate(metadata_elements):\n",
    "                if index == 1:\n",
    "                    # Regulation title\n",
    "                    title = re.search(r'Judul\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    title = title[1] if title is not None else ''\n",
    "\n",
    "                    # Regulation about\n",
    "                    about = re.search(r'Tentang (.*)', title, re.IGNORECASE)\n",
    "                    about = about[1] if about is not None else ''\n",
    "\n",
    "                    # Regulation amendment number\n",
    "                    amendment = '0'\n",
    "                    if re.search(r'^Perubahan Atas', about, re.IGNORECASE):\n",
    "                        amendment = '1'\n",
    "                    elif re.search(r'^Perubahan (.+) Atas', about, re.IGNORECASE):\n",
    "                        amendment = re.search(r'^Perubahan (.+) Atas', about, re.IGNORECASE)[1]\n",
    "                        amendment = str(self.WORD_TO_NUMBER[amendment.strip().lower()])\n",
    "\n",
    "                elif index == 3:  # Regulation number\n",
    "                    number = re.search(r'Nomor\\s(\\d+)', element.text, re.IGNORECASE)\n",
    "                    number = number[1] if number is not None else ''\n",
    "                elif index == 4:  # Regulation type\n",
    "                    regulation_type = re.search(r'Bentuk\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    regulation_type = regulation_type[1] if regulation_type is not None else ''\n",
    "                elif index == 5:  # Regulation short type\n",
    "                    short_type = re.search(r'Bentuk Singkat\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    short_type = short_type[1].upper() if short_type is not None else ''\n",
    "                elif index == 6:  # Regulation year\n",
    "                    year = re.search(r'Tahun\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    year = year[1] if year is not None else ''\n",
    "                elif index == 7:  # Regulation issue palce\n",
    "                    issue_place = re.search(r'Tempat Penetapan\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    issue_place = issue_place[1] if issue_place is not None else ''\n",
    "                elif index == 8:  # Regulation issue date\n",
    "                    issue_date = re.search(r'Tanggal Penetapan\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    if issue_date is not None:\n",
    "                        issue_date = dateparser.parse(date_string=issue_date[1], languages=['id'])\n",
    "                        issue_date = issue_date.strftime('%Y-%m-%d')\n",
    "                    else:\n",
    "                        issue_date = ''\n",
    "                elif index == 10:  # Regulation effective date\n",
    "                    effective_date = re.search(r'Tanggal Berlaku\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    if effective_date is not None:\n",
    "                        effective_date = dateparser.parse(date_string=effective_date[1], languages=['id'])\n",
    "                        effective_date = effective_date.strftime('%Y-%m-%d')\n",
    "                    else:\n",
    "                        effective_date = ''\n",
    "                elif index == 12:  # Regulation subjects\n",
    "                    subjects = re.search(r'Subjek\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    subjects = subjects[1] if subjects is not None else ''\n",
    "                    subjects = subjects.split('-')\n",
    "                    subjects = [subject.strip() for subject in subjects]\n",
    "                elif index == 13:  # Regulation status\n",
    "                    status = re.search(r'Status\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    status = status[1] if status is not None else ''\n",
    "                    if status.lower() == 'tidak berlaku':\n",
    "                        print(f'INEFFECTIVE REGULATION: {regulation_link}')\n",
    "                        ineffective = True\n",
    "                elif index == 15:  # Regulation institution\n",
    "                    institution = re.search(r'Lokasi\\s(.*)', element.text, re.IGNORECASE)\n",
    "                    institution = institution[1] if institution is not None else ''\n",
    "\n",
    "            if ineffective:\n",
    "                continue\n",
    "\n",
    "            # Create regulation ID\n",
    "            regulation_id = '{year}{type}{number}{section}{section_number}{additional_section_number}'.format(\n",
    "                year=year,\n",
    "                type=self.ENCODE['type'][short_type],\n",
    "                number=str(number).zfill(3),\n",
    "                section=self.ENCODE['section']['document'],\n",
    "                section_number='000',\n",
    "                additional_section_number='00'\n",
    "            )\n",
    "\n",
    "            # Extract download link and name\n",
    "            download_box = self.web_driver.find_element(By.XPATH, download_box_xpath)\n",
    "            download_link = download_box.find_element(By.CSS_SELECTOR, '[href]').get_attribute('href')\n",
    "            download_name = f'{short_type}_{year}_{str(number).zfill(3)}'\n",
    "\n",
    "            # Extract regulation status references\n",
    "            status_box = self.web_driver.find_element(By.XPATH, status_box_xpath)\n",
    "            \n",
    "            try:\n",
    "                status_inner_box = status_box.find_element(By.CSS_SELECTOR, status_inner_box_css_selector)\n",
    "            except NoSuchElementException as e:\n",
    "                status_inner_box = None\n",
    "            \n",
    "            repealed = list()\n",
    "            repeal = list()\n",
    "            amended = list()\n",
    "            amend = list()\n",
    "            \n",
    "            if status_inner_box is not None:\n",
    "                status_elements = status_inner_box.find_elements(By.XPATH, './*')\n",
    "                current_status = None\n",
    "                next_status = None\n",
    "\n",
    "                for element in status_elements:\n",
    "                    text = element.text.strip()\n",
    "                    current_status = next_status\n",
    "                    next_status = None\n",
    "                    \n",
    "                    if re.search(status_type_patterns, text, re.IGNORECASE):\n",
    "                        current_status = text\n",
    "                        next_status = text\n",
    "                        continue\n",
    "\n",
    "                    regulation_references = element.find_elements(By.CSS_SELECTOR, '[href]')\n",
    "                    for regulation_reference in regulation_references:\n",
    "                        href = regulation_reference.get_attribute('href')\n",
    "                        if current_status == 'Dicabut dengan :':\n",
    "                            repealed.append(href)\n",
    "                        elif current_status == 'Mencabut :':\n",
    "                            repeal.append(href)\n",
    "                        elif current_status == 'Diubah dengan :':\n",
    "                            amended.append(href)\n",
    "                        elif current_status == 'Mengubah :':\n",
    "                            amend.append(href)\n",
    "            \n",
    "            # Combine and append all metadata to regulation_metadata\n",
    "            regulation_metadata.append({\n",
    "                'id': regulation_id,                # ID peraturan\n",
    "                'url': regulation_link,             # Link Web Peraturan\n",
    "                'download_link': download_link,     # Link Download Peraturan\n",
    "                'download_name': download_name,     # Nama File Download\n",
    "                'title': title,                     # Judul Lengkap Peraturan\n",
    "                'about': about,                     # Judul Isi Peraturan\n",
    "                'type': regulation_type,            # Jenis Peraturan\n",
    "                'short_type': short_type,           # Jenis Peraturan (Singkatan)\n",
    "                'amendment': amendment,             # Nomor Amandemen\n",
    "                'number': number,                   # Nomor Peraturan\n",
    "                'year': year,                       # Tahun Peraturan\n",
    "                'institution': institution,         # Lembaga\n",
    "                'issue_place': issue_place,         # Tempat Penetapan\n",
    "                'issue_date': issue_date,           # Tanggal Penetapan\n",
    "                'effective_date': effective_date,   # Tanggal Diberlakukan\n",
    "                'subjects': subjects,               # Subjek\n",
    "                'status': {\n",
    "                    'repealed': repealed,           # Dicabut dengan ..\n",
    "                    'repeal': repeal,               # Mencabut ...\n",
    "                    'amended': amended,             # Diubah dengan ...\n",
    "                    'amend': amend                  # Mengubah ...\n",
    "                }\n",
    "            })\n",
    "\n",
    "            durations.append(time.time() - start)\n",
    "            time.sleep(2)  # Break for 2 seconds\n",
    "        \n",
    "        self.web_driver.quit()\n",
    "\n",
    "        if verbose:\n",
    "            print('=' * 76)\n",
    "            print(f'Total regulations : {len(regulation_links)} regulations')\n",
    "            print(f'Total time        : {round(sum(durations), 3)} seconds')\n",
    "            print(f'Average time      : {round(sum(durations) / len(regulation_links), 3)} seconds')\n",
    "            print('NOTE! Time records do not include the 2 seconds break between each regulation')\n",
    "            print('=' * 76)\n",
    "\n",
    "        return regulation_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'data'\n",
    "output = 'regulation_data.json'\n",
    "output_path = os.path.join(dir_path, output)\n",
    "\n",
    "web_driver = webdriver.Firefox()\n",
    "scraper = BPKScraper(web_driver=web_driver)\n",
    "regulation_metadata = scraper.regulation_metadata(\n",
    "    regulation_links=selected_regulations,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "BPKScraper.list_of_dict_to_json(\n",
    "    regulation_data=regulation_metadata,\n",
    "    output_path=output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jdih_scraper.bpk import BPKScraper\n",
    "\n",
    "# OUTPUT = 'test.json'\n",
    "# OUTPUT_PATH = os.path.join(DIR_PATH, OUTPUT)\n",
    "\n",
    "# web_driver = webdriver.Firefox()\n",
    "# scraper = BPKScraper(web_driver=web_driver)\n",
    "# regulation_data = scraper.scrape_jdih_bpk_regulation_metadata(\n",
    "#     regulation_links=selected_regulations[:5],\n",
    "#     output_path=OUTPUT_PATH,\n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ JSON\n",
    "# https://stackoverflow.com/questions/20199126/reading-json-from-a-file\n",
    "with open(output_path) as input_file:\n",
    "    json_data = json.load(input_file)\n",
    "\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data[0]['download_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creta CSV File for URL -> ID Mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_url_id = list()\n",
    "for regulation in tqdm(json_data):\n",
    "    mapping_url_id.append({\n",
    "        'url': regulation['url'],\n",
    "        'id': regulation['id'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'mapping_url_id.csv'\n",
    "output_path = os.path.join(dir_path, output)\n",
    "\n",
    "mapping_url_id_df = pd.DataFrame(mapping_url_id)\n",
    "mapping_url_id_df.to_csv(output_path, index=False)\n",
    "mapping_url_id_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modified Regulation Data Status**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mengubah url di 'status' menjadi ID jika ada di dalam Mapping URL -> ID\n",
    "- Jika tidak ada di dalam Mapping URL -> ID maka tetap biarkan dalam bentuk url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_url_id_df.loc[mapping_url_id_df['url'] == 'https://peraturan.bpk.go.id/Details/45357/uu-no-36-tahun-1999', 'id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, regulation in tqdm(enumerate(json_data)):\n",
    "    for status, values in regulation['status'].items():\n",
    "        temp_list = list()\n",
    "        for val in values:\n",
    "            mapping_value = mapping_url_id_df.loc[mapping_url_id_df['url'] == val, 'id'].values\n",
    "            mapping_value = str(mapping_value[0]) if len(mapping_value) > 0 else val\n",
    "            temp_list.append(mapping_value)\n",
    "            # KALAU MAU URL DIHAPUS\n",
    "            # if mapping_value != val:\n",
    "                # temp_list.append(mapping_value)\n",
    "        json_data[index]['status'][status] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'regulation_data_modified.json'\n",
    "output_path = os.path.join(dir_path, output)\n",
    "\n",
    "output_json_str = BPKScraper.list_of_dict_to_json(json_data, output_path)\n",
    "print(f'Successfully saved {len(json_data)} regulatory data to {output_path}')\n",
    "\n",
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create EXCEL File for Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIDAK JADI.\n",
    "\n",
    "Karena aku sekarang aku melakukan filtering dulu, baru melakukan semua yang di atas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering_data = list()\n",
    "# for regulation in tqdm(json_data):\n",
    "#     filtering_data.append({\n",
    "#         'id': regulation['id'],\n",
    "#         'name': regulation['download_name'],\n",
    "#         'about': regulation['about'],\n",
    "#         'subjects': regulation['subjects'],\n",
    "#         'url': regulation['url'],\n",
    "#         'used': False\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering_data_df = pd.DataFrame(filtering_data)\n",
    "# filtering_data_df.to_excel(os.path.join('output', 'regulation_data_filtering_real.xlsx'), index=False)\n",
    "# filtering_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Arsip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_regulation_data(links: list[str]) -> list[dict]:\n",
    "#     metadata_box_xpath = '/html/body/div/div/div[2]/div[2]/div/div[1]/div[2]/div'\n",
    "#     download_box_xpath = '/html/body/div/div/div[2]/div[2]/div/div[2]/div[1]'\n",
    "#     status_box_xpath = '/html/body/div/div/div[2]/div[2]/div/div[2]/div[2]'\n",
    "#     metadata_inner_box_css_selector = 'div.container.fs-6'\n",
    "#     status_inner_box_css_selector = 'div.container.fs-6'\n",
    "#     status_type_patterns = r'(Dicabut dengan :|Diubah dengan :|Mengubah :|Mencabut :)'\n",
    "\n",
    "#     driver = webdriver.Firefox()\n",
    "#     regulation_data = list()\n",
    "\n",
    "#     for regulation_link in tqdm(iterable=links, desc='Scraping regulation data'):\n",
    "#         # print(f'{str(regulation_index + 1).zfill(3)}. {regulation_link}')\n",
    "#         driver.get(regulation_link)\n",
    "#         wait = WebDriverWait(driver, timeout=5)\n",
    "#         wait.until(EC.presence_of_element_located((By.XPATH, metadata_box_xpath)))\n",
    "#         wait.until(EC.presence_of_element_located((By.XPATH, download_box_xpath)))\n",
    "\n",
    "#         # EXTRACT METADATA\n",
    "#         ineffective = False\n",
    "#         metadata_box = driver.find_element(By.XPATH, metadata_box_xpath)\n",
    "#         metadata_inner_box = metadata_box.find_element(By.CSS_SELECTOR, metadata_inner_box_css_selector)\n",
    "#         metadata_elements = metadata_inner_box.find_elements(By.XPATH, './*')[:-2]\n",
    "\n",
    "#         for index, element in enumerate(metadata_elements):\n",
    "#             if index == 1:  # Regulation title and about\n",
    "#                 title = re.search(r'Judul\\s(.*)', element.text)\n",
    "#                 title = title[1] if title is not None else ''\n",
    "#                 about = re.search(r'[Tt]entang (.*)', title)\n",
    "#                 about = about[1] if about is not None else ''\n",
    "#             elif index == 3:  # Regulation number\n",
    "#                 number = re.search(r'Nomor\\s(\\d+)', element.text)\n",
    "#                 number = number[1] if number is not None else ''\n",
    "#                 # old_numbering = re.search(r'(\\d+)\\/', new_numbering[0])\n",
    "#                 # number = new_numbering[1] if old_numbering is None else old_numbering[1]\n",
    "#             elif index == 4:  # Regulation type\n",
    "#                 regulation_type = re.search(r'Bentuk\\s(.*)', element.text)\n",
    "#                 regulation_type = regulation_type[1] if regulation_type is not None else ''\n",
    "#             elif index == 5:  # Regulation short type\n",
    "#                 short_type = re.search(r'Bentuk Singkat\\s(.*)', element.text)\n",
    "#                 short_type = short_type[1].upper() if short_type is not None else ''\n",
    "#             elif index == 6:  # Regulation year\n",
    "#                 year = re.search(r'Tahun\\s(.*)', element.text)\n",
    "#                 year = year[1] if year is not None else ''\n",
    "#             elif index == 7:  # Regulation issue palce\n",
    "#                 issue_place = re.search(r'Tempat Penetapan\\s(.*)', element.text)\n",
    "#                 issue_place = issue_place[1] if issue_place is not None else ''\n",
    "#             elif index == 8:  # Regulation issue date\n",
    "#                 issue_date = re.search(r'Tanggal Penetapan\\s(.*)', element.text)\n",
    "#                 if issue_date is not None:\n",
    "#                     issue_date = dateparser.parse(date_string=issue_date[1], languages=['id'])\n",
    "#                     issue_date = issue_date.strftime('%Y-%m-%d')\n",
    "#                 else:\n",
    "#                     issue_date = ''\n",
    "#             elif index == 10:  # Regulation effective date\n",
    "#                 effective_date = re.search(r'Tanggal Berlaku\\s(.*)', element.text)\n",
    "#                 if effective_date is not None:\n",
    "#                     effective_date = dateparser.parse(date_string=effective_date[1], languages=['id'])\n",
    "#                     effective_date = effective_date.strftime('%Y-%m-%d')\n",
    "#                 else:\n",
    "#                     effective_date = ''\n",
    "#             elif index == 12:  # Regulation subjects\n",
    "#                 subjects = re.search(r'Subjek\\s(.*)', element.text)\n",
    "#                 subjects = subjects[1] if subjects is not None else ''\n",
    "#                 subjects = subjects.split('-')\n",
    "#                 subjects = [subject.strip() for subject in subjects]\n",
    "#             elif index == 13:  # Regulation status\n",
    "#                 status = re.search(r'Status\\s(.*)', element.text)\n",
    "#                 status = status[1] if status is not None else ''\n",
    "#                 if status.lower() == 'tidak berlaku':\n",
    "#                     print(f'INEFFECTIVE REGULATION: {regulation_link}')\n",
    "#                     ineffective = True\n",
    "#             elif index == 15:  # Regulation institution\n",
    "#                 institution = re.search(r'Lokasi\\s(.*)', element.text)\n",
    "#                 institution = institution[1] if institution is not None else ''\n",
    "\n",
    "#         if ineffective:\n",
    "#             continue\n",
    "\n",
    "#         # TODO: Ubah '05' menyesuaikan dengan tipe peraturan\n",
    "#         # 'type': {\n",
    "#         #     'UU': '01',\n",
    "#         #     'PERPPU': '02',\n",
    "#         #     'PP': '03',\n",
    "#         #     'PERPRES': '04',\n",
    "#         #     'PERMENKOMINFO': '05'\n",
    "#         # },\n",
    "#         regulation_id = f'{year}05{str(number).zfill(3)}1000'\n",
    "\n",
    "#         # EXTRACT DOWNLOAD LNK AND FILENAME\n",
    "#         download_box = driver.find_element(By.XPATH, download_box_xpath)\n",
    "#         download_link = download_box.find_element(By.CSS_SELECTOR, '[href]').get_attribute('href')\n",
    "#         download_name = f'{short_type}_{str(number).zfill(3)}_{year}'\n",
    "\n",
    "#         # EXTRACT REGULATION STATUS REFERENCE\n",
    "#         status_box = driver.find_element(By.XPATH, status_box_xpath)\n",
    "        \n",
    "#         try:\n",
    "#             status_inner_box = status_box.find_element(By.CSS_SELECTOR, status_inner_box_css_selector)\n",
    "#         except NoSuchElementException as e:\n",
    "#             status_inner_box = None\n",
    "        \n",
    "#         repealed = list()\n",
    "#         repeal = list()\n",
    "#         amended = list()\n",
    "#         amend = list()\n",
    "        \n",
    "#         if status_inner_box is not None:\n",
    "#             status_elements = status_inner_box.find_elements(By.XPATH, './*')\n",
    "#             current_status = None\n",
    "#             next_status = None\n",
    "\n",
    "#             for element in status_elements:\n",
    "#                 text = element.text.strip()\n",
    "#                 current_status = next_status\n",
    "#                 next_status = None\n",
    "                \n",
    "#                 if re.search(status_type_patterns, text):\n",
    "#                     current_status = text\n",
    "#                     next_status = text\n",
    "#                     continue\n",
    "                \n",
    "#                 # https://peraturan.bpk.go.id/Details/203070/permenkominfo-no-5-tahun-2021\n",
    "#                 # Kasus unik, di mana Mencabut sebagian masuk ke dalam mencabut\n",
    "#                 # SUDAH SOLVED\n",
    "#                 regulation_references = element.find_elements(By.CSS_SELECTOR, '[href]')\n",
    "#                 for regulation_reference in regulation_references:\n",
    "#                     href = regulation_reference.get_attribute('href')\n",
    "#                     if current_status == 'Dicabut dengan :':\n",
    "#                         repealed.append(href)\n",
    "#                     elif current_status == 'Mencabut :':\n",
    "#                         repeal.append(href)\n",
    "#                     elif current_status == 'Diubah dengan :':\n",
    "#                         amended.append(href)\n",
    "#                     elif current_status == 'Mengubah :':\n",
    "#                         amend.append(href)\n",
    "\n",
    "\n",
    "        \n",
    "#         # COMBINE ALL DATA AND APPEND TO regulation_data\n",
    "#         data = {\n",
    "#             'id': regulation_id,                # ID peraturan\n",
    "#             'url': regulation_link,             # Link Web Peraturan\n",
    "#             'download_link': download_link,     # Link Download Peraturan\n",
    "#             'download_name': download_name,     # Nama File Download\n",
    "#             'title': title,                     # Judul Lengkap Peraturan\n",
    "#             'about': about,                     # Judul Isi Peraturan\n",
    "#             'type': regulation_type,            # Jenis Peraturan\n",
    "#             'short_type': short_type,           # Jenis Peraturan (Singkatan)\n",
    "#             'number': number,                   # Nomor Peraturan\n",
    "#             'year': year,                       # Tahun Peraturan\n",
    "#             'institution': institution,         # Lembaga\n",
    "#             'issue_place': issue_place,         # Tempat Penetapan\n",
    "#             'issue_date': issue_date,           # Tanggal Penetapan\n",
    "#             'effective_date': effective_date,   # Tanggal Diberlakukan\n",
    "#             'subjects': subjects,               # Subjek\n",
    "#             'status': {\n",
    "#                 'repealed': repealed,           # Dicabut dengan ..\n",
    "#                 'repeal': repeal,               # Mencabut ...\n",
    "#                 'amended': amended,             # Diubah dengan ...\n",
    "#                 'amend': amend                  # Mengubah ...\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#         regulation_data.append(data)\n",
    "        \n",
    "#         # WAIT 2 SECOND FOR THE NEXT REGULATION\n",
    "#         time.sleep(2)\n",
    "    \n",
    "#     driver.quit()\n",
    "    \n",
    "#     return regulation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.freecodecamp.org/news/how-to-pretty-print-json-in-python/\n",
    "# # https://www.geeksforgeeks.org/how-to-convert-python-dictionary-to-json/\n",
    "# # Convert the data to a JSON formatted string with 4 spaces of indentation\n",
    "# def list_of_dict_to_json(data: list[dict], output_name: str) -> str:\n",
    "#     if not output_name.endswith('.json'):\n",
    "#         output_name = output_name + '.json'\n",
    "#     with open(output_name, 'w') as output_file:\n",
    "#         json.dump(data, output_file, indent=4)\n",
    "#         output_json_str = json.dumps(data, indent=4)\n",
    "#         return output_json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regulation_data = scrape_regulation_data(selected_regulations)\n",
    "# print(f'[INFO] Successfully scraping {len(regulation_data)} regulatory data')\n",
    "\n",
    "# OUTPUT = 'regulation_data.json'\n",
    "# OUTPUT_PATH = os.path.join(DIR_PATH, OUTPUT)\n",
    "# output_json_str = list_of_dict_to_json(regulation_data, OUTPUT_PATH)\n",
    "# print(f'[INFO] Successfully saved {len(regulation_data)} regulatory data to {OUTPUT_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # READ JSON\n",
    "# # https://stackoverflow.com/questions/20199126/reading-json-from-a-file\n",
    "# with open(OUTPUT_PATH) as input_file:\n",
    "#     json_data = json.load(input_file)\n",
    "\n",
    "# json_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
