{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas import evaluate, EvaluationDataset, RunConfig\n",
    "from ragas.metrics import AnswerAccuracy, ResponseRelevancy, RougeScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37102a0",
   "metadata": {},
   "source": [
    "## **Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9daf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join(\"results\", \"end_to_end_graph_rag\")\n",
    "DATASET_PATH = os.path.join(\"data\", \"testing_dataset.xlsx\")\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "df = pd.read_excel(DATASET_PATH)\n",
    "dataset = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row[\"is_valid\"]:\n",
    "        dataset.append(\n",
    "            {\n",
    "                \"user_input\": str(row[\"user_input\"]),\n",
    "                \"reference\": str(row[\"reference\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)\n",
    "\n",
    "len(evaluation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbaa836",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6aff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAUDE_LLM_MODEL_NAME = \"claude-3-5-haiku-20241022\"\n",
    "GEMINI_LLM_MODEL_NAME = \"gemini-2.0-flash\"\n",
    "EMBEDDING_MODEL_NAME = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "claude_llm = ChatAnthropic(\n",
    "    model_name=CLAUDE_LLM_MODEL_NAME,\n",
    "    max_tokens_to_sample=4096,\n",
    "    temperature=0.0,\n",
    "    timeout=None,\n",
    "    api_key=os.environ[\"ANTHROPIC_API_KEY\"],\n",
    ")\n",
    "\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=GEMINI_LLM_MODEL_NAME,\n",
    "    temperature=0.0,\n",
    "    timeout=None,\n",
    "    api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    ")\n",
    "\n",
    "llm_evaluator = gemini_llm\n",
    "embedding_evaluator = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67312199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_dataset_or_result(\n",
    "    dataset,\n",
    "    experiment_name\n",
    ") -> None:\n",
    "    dataset.to_pandas().to_json(\n",
    "        os.path.join(OUTPUT_PATH, f\"{experiment_name}.json\"),\n",
    "        orient=\"records\",\n",
    "    )\n",
    "\n",
    "def run_test_case(test_case: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    experiment_name = (\n",
    "        f\"{test_case['llm_model'].model}_non_rag\"\n",
    "    ).replace(\"/\", \"-\").replace(\":\", \"-\")\n",
    "\n",
    "    for data in tqdm(\n",
    "        iterable=evaluation_dataset,\n",
    "        desc=f\"Running LLM non-RAG: `{experiment_name}`\",\n",
    "        disable=False,\n",
    "    ):    \n",
    "        response = test_case[\"llm_model\"].invoke(data.user_input)\n",
    "        data.response = str(response.content)\n",
    "\n",
    "    # Checkpoint 1\n",
    "    save_experiment_dataset_or_result(evaluation_dataset, experiment_name)\n",
    "\n",
    "    run_config = RunConfig(timeout=None)\n",
    "\n",
    "    evaluation_result = evaluate(\n",
    "        dataset=EvaluationDataset.from_list(dataset),\n",
    "        metrics=[\n",
    "            RougeScore(rouge_type=\"rougeL\", mode=\"fmeasure\", name=\"rougeL_fmeasure\"),\n",
    "            ResponseRelevancy(),\n",
    "            AnswerAccuracy(),\n",
    "        ],\n",
    "        llm=LangchainLLMWrapper(llm_evaluator, run_config=run_config),\n",
    "        embeddings=LangchainEmbeddingsWrapper(embedding_evaluator, run_config=run_config),\n",
    "        experiment_name=experiment_name,\n",
    "        run_config=run_config,\n",
    "    )\n",
    "\n",
    "    # Checkpoint 2\n",
    "    save_experiment_dataset_or_result(evaluation_result, experiment_name)\n",
    "\n",
    "    return {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"args\": {\"llm\": test_case[\"llm_model\"].model},\n",
    "        \"evaluation_result\": evaluation_result,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06eaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\"llm_model\": claude_llm},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556173f1",
   "metadata": {},
   "source": [
    "### **Test Case 1**\n",
    "\n",
    "- Claude 3.5 Haiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_1 = run_test_case(test_cases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(test_result_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
